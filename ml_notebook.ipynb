{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQTJMv2c-Ec5",
        "outputId": "e353e396-b11f-4d3b-97ad-dfbdf4261131"
      },
      "source": [
        "! pip install category_encoders"
      ],
      "id": "UQTJMv2c-Ec5",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "promising-system",
        "outputId": "4727b2b4-e7bb-4f0e-803d-dbaa774ef744"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from category_encoders import *\n",
        "from sklearn.preprocessing import *\n",
        "from imblearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.compose import *\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import *\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "warnings.simplefilter(\"ignore\", FutureWarning)"
      ],
      "id": "promising-system",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "serious-homework"
      },
      "source": [
        "### Table of Contents\n",
        "\n",
        "* [Background](#Background)\n",
        "    * [Load in data](#Load_in_data)\n",
        "        * [Encode target](#Encode_target)\n",
        "        * [Missing values](#Missing_values)   \n",
        "        * [Imbalanced data](#Imbalanced_data)\n",
        "    * [Split data](#Split_data)\n",
        "    * [Metrics](#Metrics)\n",
        "    * [Choose algorithms](#Choose_algorithms)\n",
        "        \n",
        "* [Logistic Regression](#LogisticRegression)\n",
        "    * [SMOTE](#lr_smote)\n",
        "    * [Column transformations](#lr_encoding)\n",
        "        * [Categorical](#lr_categorical)\n",
        "        * [Numeric](#lr_continuous) \n",
        "        * [Combined](#lr_combined_encoders) \n",
        "    * [Tune hyperparameters](#lr_hyperparameters)\n",
        "\n",
        "* [Random Forest](#RandomForest)\n",
        "    * [SMOTE](#rf_smote)\n",
        "    * [Column transformations](#rf_encoding)\n",
        "        * [Categorical](#rf_categorical)\n",
        "        * [Numeric](#rf_continuous) \n",
        "        * [Combined](#rf_combined_encoders) \n",
        "    * [Tune hyperparameters](#rf_hyperparameters)\n",
        "\n",
        "* [Final Model](#Final_model)\n",
        "    * [Conclusion](#Conclusion)\n",
        "    * [Future directions](#Future_directions)"
      ],
      "id": "serious-homework"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "derived-israel"
      },
      "source": [
        "### Background"
      ],
      "id": "derived-israel"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "municipal-manitoba"
      },
      "source": [
        "The data used here comes from the UCI Machine Learning Repository; it is the \"Drug consumption (quantified)\" dataset. The dataset can be found at [this url.](https://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29#)\n",
        "\n",
        "The data itself was collected via online survery from 1885 participants. The data collected includes demographic information, such as age, gender, education, country of residence, and ethnicity, personality inventory scores on traits such as neuroticism, extraversion, openness to experience, agreeableness, conscientiousness, impulsivity, and sensation seeking. In addition to these attributes, level of consumption of 18 drugs such as alcohol, amphetamines, amyl nitrite, benzodiazepine, cannabis, chocolate, cocaine, caffeine, crack, ecstasy, heroin, ketamine, legal highs, LSD, methadone, mushrooms, nicotine and volatile substance abuse were collected. To disqualify any potential participants who wanted to over-report use of drugs, participants also reported their consumption of a fake drug called \"Semeron\". \n",
        "\n",
        "Participants were given 7 levels of consumption to choose from for each drug, \"Never Used\", \"Used over a Decade Ago\", \"Used in Last Decade\", \"Used in Last Year\", \"Used in Last Month\", \"Used in Last Week\", and \"Used in Last Day\".\n",
        "\n",
        "In this notebook, I've decided to try to predict the level of participants' use of cannabis based on the collected demographic and personality inventory scores using machine learning. Here, I try two different machine learning algorithms to predict level of cannabis use: a logistic regression classifier model and a random forest classifier model.\n",
        "\n",
        "** Note that the original data on the UCI website has been transformed from categorical values to a scaled numeric value, I simply converted the scaled numeric values back to their original categorical values and use the converted data in this notebook."
      ],
      "id": "municipal-manitoba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "human-bronze"
      },
      "source": [
        "### Load in data <a class=\"anchor\" id=\"Load_in_data\"></a>"
      ],
      "id": "human-bronze"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "abroad-satisfaction",
        "outputId": "9a24351b-53b1-4316-e375-07d5390104b7"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/audreybarszcz/drug_consumption_machine_learning/main/drug_consumption.csv'\n",
        "data = pd.read_csv(url)\n",
        "data.head()"
      ],
      "id": "abroad-satisfaction",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Education</th>\n",
              "      <th>Country</th>\n",
              "      <th>Ethnicity</th>\n",
              "      <th>Nscore</th>\n",
              "      <th>Escore</th>\n",
              "      <th>Oscore</th>\n",
              "      <th>Ascore</th>\n",
              "      <th>Cscore</th>\n",
              "      <th>Impulsive</th>\n",
              "      <th>SS</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Amphet</th>\n",
              "      <th>Amyl</th>\n",
              "      <th>Benzos</th>\n",
              "      <th>Caff</th>\n",
              "      <th>Cannabis</th>\n",
              "      <th>Choc</th>\n",
              "      <th>Coke</th>\n",
              "      <th>Crack</th>\n",
              "      <th>Ecstasy</th>\n",
              "      <th>Heroin</th>\n",
              "      <th>Ketamine</th>\n",
              "      <th>Legalh</th>\n",
              "      <th>LSD</th>\n",
              "      <th>Meth</th>\n",
              "      <th>Mushrooms</th>\n",
              "      <th>Nicotine</th>\n",
              "      <th>Semer</th>\n",
              "      <th>VSA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>35-44</td>\n",
              "      <td>Female</td>\n",
              "      <td>Professional certificate/ diploma</td>\n",
              "      <td>UK</td>\n",
              "      <td>Mixed-White/Asian</td>\n",
              "      <td>39.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>-0.21712</td>\n",
              "      <td>-1.18084</td>\n",
              "      <td>CL5</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL6</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL5</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>25-34</td>\n",
              "      <td>Male</td>\n",
              "      <td>Doctorate degree</td>\n",
              "      <td>UK</td>\n",
              "      <td>White</td>\n",
              "      <td>29.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>-0.71126</td>\n",
              "      <td>-0.21575</td>\n",
              "      <td>CL5</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL6</td>\n",
              "      <td>CL4</td>\n",
              "      <td>CL6</td>\n",
              "      <td>CL3</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL4</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL3</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL4</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>35-44</td>\n",
              "      <td>Male</td>\n",
              "      <td>Professional certificate/ diploma</td>\n",
              "      <td>UK</td>\n",
              "      <td>White</td>\n",
              "      <td>31.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>-1.37983</td>\n",
              "      <td>0.40148</td>\n",
              "      <td>CL6</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL6</td>\n",
              "      <td>CL3</td>\n",
              "      <td>CL4</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL1</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>18-24</td>\n",
              "      <td>Female</td>\n",
              "      <td>Masters degree</td>\n",
              "      <td>UK</td>\n",
              "      <td>White</td>\n",
              "      <td>34.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>-1.37983</td>\n",
              "      <td>-1.18084</td>\n",
              "      <td>CL4</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL3</td>\n",
              "      <td>CL5</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL4</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>35-44</td>\n",
              "      <td>Female</td>\n",
              "      <td>Doctorate degree</td>\n",
              "      <td>UK</td>\n",
              "      <td>White</td>\n",
              "      <td>43.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>-0.21712</td>\n",
              "      <td>-0.21575</td>\n",
              "      <td>CL4</td>\n",
              "      <td>CL1</td>\n",
              "      <td>CL1</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL6</td>\n",
              "      <td>CL3</td>\n",
              "      <td>CL6</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL1</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL1</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL2</td>\n",
              "      <td>CL0</td>\n",
              "      <td>CL0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID    Age  Gender  ... Nicotine Semer  VSA\n",
              "0   1  35-44  Female  ...      CL2   CL0  CL0\n",
              "1   2  25-34    Male  ...      CL4   CL0  CL0\n",
              "2   3  35-44    Male  ...      CL0   CL0  CL0\n",
              "3   4  18-24  Female  ...      CL2   CL0  CL0\n",
              "4   5  35-44  Female  ...      CL2   CL0  CL0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "according-memorabilia"
      },
      "source": [
        "X = data.iloc[:, 1:13] # feature columns, ignoring ID column\n",
        "y = data.iloc[:, 18]   # cannabis use column"
      ],
      "id": "according-memorabilia",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aerial-header"
      },
      "source": [
        "#### Encode target <a class=\"anchor\" id=\"Encode_target\"></a>"
      ],
      "id": "aerial-header"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "numerous-marijuana"
      },
      "source": [
        "# transform y from string categories to numeric values\n",
        "le = LabelEncoder().fit(y)\n",
        "y = le.transform(y)"
      ],
      "id": "numerous-marijuana",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reflected-birmingham"
      },
      "source": [
        "#### Missing values <a class=\"anchor\" id=\"Missing_values\"></a>"
      ],
      "id": "reflected-birmingham"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "printable-garbage",
        "outputId": "f8d31691-e850-4e58-b774-05062f6ba108"
      },
      "source": [
        "# luckily we have no missing values to impute!\n",
        "data.isna().sum().sum()"
      ],
      "id": "printable-garbage",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "desirable-example"
      },
      "source": [
        "#### Imbalanced data <a class=\"anchor\" id=\"Imbalanced_data\"></a>\n",
        "Looking at the distribution of class labels y, there may be some class imbalance. For example, the class 0 (Never Used) and class 6 (Used in the last day) labels occur 2-3 times more often than classes 4 (Used in last month) or 5 (Used in last week). In an effort to make our predictions better, try adding SMOTE to our pipeline."
      ],
      "id": "desirable-example"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iraqi-worthy",
        "outputId": "eb651795-211d-49b5-db55-35f66dbec0d6"
      },
      "source": [
        "# relative proportion of each label\n",
        "data.groupby('Cannabis').count()['Age']/data.groupby('Cannabis').count()['Age'].sum()"
      ],
      "id": "iraqi-worthy",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cannabis\n",
              "CL0    0.219098\n",
              "CL1    0.109814\n",
              "CL2    0.141114\n",
              "CL3    0.111936\n",
              "CL4    0.074271\n",
              "CL5    0.098143\n",
              "CL6    0.245623\n",
              "Name: Age, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "protecting-window"
      },
      "source": [
        "### Split data <a class=\"anchor\" id=\"Split_data\"></a>"
      ],
      "id": "protecting-window"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "romantic-surgeon"
      },
      "source": [
        "I chose 0.15 to use as the test data, leaving 0.85 remaining to split into training and validation sets. I again used a split of 0.15 for validation, 12.75% of the original data, and 0.85 for training, 72.25% of the original data. I wanted to split the data such that I would have about 75% of the data to train on."
      ],
      "id": "romantic-surgeon"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "british-thermal"
      },
      "source": [
        "# split off test data and never use until the end!!!\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y.ravel(), test_size=0.15)"
      ],
      "id": "british-thermal",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "engaged-insurance"
      },
      "source": [
        "# split training set again into training and validation set\n",
        "X_train_train, X_val, y_train_train, y_val = train_test_split(X_train, y_train, test_size=0.15)"
      ],
      "id": "engaged-insurance",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "affected-negotiation"
      },
      "source": [
        "### Metrics <a class=\"anchor\" id=\"Metrics\"></a>"
      ],
      "id": "affected-negotiation"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miniature-mileage"
      },
      "source": [
        "For evaluating performance of each model, I am looking at both balanced accuracy score and the F1-weighted score. I feel that the F1-weighted score is a more accurate measure of performance of my model since it takes into account the class weights in addition to considering both precision and recall. Whereas, the balanced accuracy score simply averages the recall scores of each class, weighting each class equally. Therefore, I use F1-weighted as my scoring metric in the RandomizedSearchCV. "
      ],
      "id": "miniature-mileage"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "promising-oracle"
      },
      "source": [
        "# helpful for trying different algorithms\n",
        "class DummyEstimator(BaseEstimator):\n",
        "    def fit(self): pass\n",
        "    def score(self): pass\n",
        "    \n",
        "\n",
        "# helpful for trying different encoders/scalers\n",
        "class DummyTransformer(TransformerMixin):\n",
        "    def fit(self): pass\n",
        "    def transform(self): pass\n",
        "\n",
        "\n",
        "def fit_and_predict_random(grid, iterations):\n",
        "    # search for best tranformer/algorithm\n",
        "    # print out its scores and parameters\n",
        "    rand = RandomizedSearchCV(estimator=pipe, \n",
        "                              param_distributions=grid, \n",
        "                              n_iter=iterations,\n",
        "                              cv=5, \n",
        "                              scoring='f1_weighted',\n",
        "                              n_jobs=-1,\n",
        "                              verbose=1)\n",
        "\n",
        "    best_model = rand.fit(X_train_train, y_train_train)\n",
        "    y_pred = rand.predict(X_val)\n",
        "    print('Balanced Accuracy:', balanced_accuracy_score(y_val, y_pred))\n",
        "    print('F1 weighted:', f1_score(y_val, y_pred, average='weighted'))\n",
        "    print(best_model.best_estimator_.get_params()['random'])\n",
        "    pass\n",
        "\n",
        "\n",
        "def fit_predict_pipe(X_train, y_train, X_test, y_test, pipe):\n",
        "    # fit the pipe, get predictions and print out metrics\n",
        "    model = pipe.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print('Balanced Accuracy:', balanced_accuracy_score(y_test, y_pred))\n",
        "    print('F1 weighted:', f1_score(y_test, y_pred, average='weighted'))\n",
        "    pass\n",
        "\n",
        "\n",
        "def best_random_column(algorithm, grid, iterations, column):\n",
        "    # try different transformers for different columns, using respective model\n",
        "    pipe = Pipeline([('random', DummyTransformer()), \n",
        "                     ('model', algorithm)])\n",
        "\n",
        "    rand = RandomizedSearchCV(estimator=pipe, \n",
        "                              param_distributions=grid, \n",
        "                              n_iter=iterations,\n",
        "                              cv=5, \n",
        "                              scoring='f1_weighted',\n",
        "                              n_jobs=-1,\n",
        "                              verbose=1)\n",
        "    \n",
        "    if X_train_train.iloc[:, column].dtype == 'float64':\n",
        "        best_model = rand.fit(X_train_train.iloc[:, column].values \\\n",
        "                              .reshape(-1, 1), y_train_train)\n",
        "        \n",
        "    else:\n",
        "        best_model = rand.fit(X_train_train.iloc[:, column], y_train_train)\n",
        "    print(best_model.best_estimator_.get_params()['random'])\n",
        "    pass\n",
        "\n",
        "\n",
        "def best_random_column_tuning(algorithm, transformer, grid, iterations, column):\n",
        "    # try different transformer hyperparameters for different columns, using respective model\n",
        "    pipe = Pipeline([('random', transformer), \n",
        "                     ('model', algorithm)])\n",
        "\n",
        "    rand = RandomizedSearchCV(estimator=pipe, \n",
        "                              param_distributions=grid, \n",
        "                              n_iter=iterations,\n",
        "                              cv=5, \n",
        "                              scoring='f1_weighted',\n",
        "                              n_jobs=-1,\n",
        "                              verbose=1)\n",
        "    \n",
        "    if X_train_train.iloc[:, column].dtype == 'float64':\n",
        "        best_model = rand.fit(X_train_train.iloc[:, column].values \\\n",
        "                              .reshape(-1, 1), y_train_train)\n",
        "        \n",
        "    else:\n",
        "        best_model = rand.fit(X_train_train.iloc[:, column], y_train_train)\n",
        "    print(best_model.best_estimator_.get_params()['random'])\n",
        "    pass"
      ],
      "id": "promising-oracle",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spread-roommate"
      },
      "source": [
        "### Choose algorithms <a class=\"anchor\" id=\"Choose_algorithms\"></a>"
      ],
      "id": "spread-roommate"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "premier-force"
      },
      "source": [
        "I wanted to try two different models from sklearn, one from outside the ensemble module and one from the ensemble module."
      ],
      "id": "premier-force"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "comfortable-disability"
      },
      "source": [
        "# not including algorithms from sklearn.ensemble module\n",
        "algorithms = [{'random': [BernoulliNB()]},\n",
        "              {'random': [DecisionTreeClassifier()]},\n",
        "              {'random': [ExtraTreeClassifier()]},\n",
        "              {'random': [GaussianNB()]},\n",
        "              {'random': [LogisticRegression(multi_class='multinomial', max_iter=1000)]},\n",
        "              {'random': [RidgeClassifier()]}]"
      ],
      "id": "comfortable-disability",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "color-venezuela"
      },
      "source": [
        "# basic bare minimum scaling/encoding\n",
        "categorical_cols = (X.dtypes == 'object')\n",
        "\n",
        "categorical_pipe = Pipeline([('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "continuous_pipe = Pipeline([('scaler', StandardScaler())])\n",
        "\n",
        "preprocessing = ColumnTransformer([('categorical', categorical_pipe,  categorical_cols),\n",
        "                                   ('continuous',  continuous_pipe, ~categorical_cols)])\n",
        "\n",
        "pipe = Pipeline([('preprocessing', preprocessing), \n",
        "                 ('random', DummyEstimator())])"
      ],
      "id": "color-venezuela",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "metallic-professional",
        "outputId": "e63486da-6db1-4456-e758-562758f4b0c3"
      },
      "source": [
        "# search for best basic algorithm from outside ensemble module\n",
        "fit_and_predict_random(algorithms, 6)"
      ],
      "id": "metallic-professional",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    2.4s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Balanced Accuracy: 0.29748756247203456\n",
            "F1 weighted: 0.33522357656205837\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "played-doctor"
      },
      "source": [
        "# best model among ensemble module\n",
        "algorithms = [{'random': [ExtraTreesClassifier()]},\n",
        "              {'random': [RandomForestClassifier()]}]"
      ],
      "id": "played-doctor",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "excellent-queue",
        "outputId": "19110a74-6417-4060-de92-06f540d3cedf"
      },
      "source": [
        "# search for best basic algorithm from outside ensemble module\n",
        "fit_and_predict_random(algorithms, 2)"
      ],
      "id": "excellent-queue",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Balanced Accuracy: 0.2816305990995432\n",
            "F1 weighted: 0.3207117088631001\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "solar-metropolitan"
      },
      "source": [
        "### LogisticRegression"
      ],
      "id": "solar-metropolitan"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "civil-hayes",
        "outputId": "6b9948cc-4c9d-40a4-c87a-e6330f317bbf"
      },
      "source": [
        "# baseline LogisticRegression performance without SMOTE\n",
        "pipe = Pipeline([('preprocess', preprocessing),\n",
        "                 ('lr', LogisticRegression(multi_class='multinomial', max_iter=1000))])\n",
        "\n",
        "fit_predict_pipe(X_train_train, y_train_train, X_val, y_val, pipe)"
      ],
      "id": "civil-hayes",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced Accuracy: 0.29748756247203456\n",
            "F1 weighted: 0.33522357656205837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "incorporated-breast"
      },
      "source": [
        "#### SMOTE <a class=\"anchor\" id=\"lr_smote\"></a>"
      ],
      "id": "incorporated-breast"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raising-centre"
      },
      "source": [
        "# try adding SMOTE to LogisticRegression\n",
        "pipe = Pipeline([('preprocess', preprocessing),\n",
        "                 ('random', SMOTE()), \n",
        "                 ('lr', LogisticRegression(multi_class='multinomial', max_iter=1000))])"
      ],
      "id": "raising-centre",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bronze-compiler"
      },
      "source": [
        "# hyperparameter grid for SMOTE\n",
        "strategy = ['minority', 'not minority', 'not majority', 'all', 'auto']\n",
        "neighbors = [1, 3, 5, 7, 9]\n",
        "\n",
        "hyperparameters = [{'random': [SMOTE()],\n",
        "                    'random__sampling_strategy': strategy,\n",
        "                    'random__k_neighbors': neighbors}]"
      ],
      "id": "bronze-compiler",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nearby-colors",
        "outputId": "a152980e-442a-40ba-ce01-36778e2df1f0"
      },
      "source": [
        "# adding does not seem to help LogisticRegression\n",
        "fit_and_predict_random(hyperparameters, 25)"
      ],
      "id": "nearby-colors",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   10.3s\n",
            "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   28.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Balanced Accuracy: 0.2730686282316717\n",
            "F1 weighted: 0.3131196417251318\n",
            "SMOTE(k_neighbors=7, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
            "      out_step='deprecated', random_state=None, ratio=None,\n",
            "      sampling_strategy='minority', svm_estimator='deprecated')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quality-monthly"
      },
      "source": [
        "#### Column Transformations <a class=\"anchor\" id=\"lr_encoding\"></a>\n",
        "As a baseline, I am just using one-hot encoding for all categorical columns and StandardScaler for all numeric columns. Maybe different encodings could make the models better."
      ],
      "id": "quality-monthly"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bridal-weapon"
      },
      "source": [
        "##### Categorical columns <a class=\"anchor\" id=\"lr_categorical\"></a>"
      ],
      "id": "bridal-weapon"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qualified-coverage",
        "outputId": "538ae1a5-a981-4697-8ad2-307846ffead2"
      },
      "source": [
        "# columns 0-4 are categorical\n",
        "categorical_cols"
      ],
      "id": "qualified-coverage",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age           True\n",
              "Gender        True\n",
              "Education     True\n",
              "Country       True\n",
              "Ethnicity     True\n",
              "Nscore       False\n",
              "Escore       False\n",
              "Oscore       False\n",
              "Ascore       False\n",
              "Cscore       False\n",
              "Impulsive    False\n",
              "SS           False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owned-ethnic",
        "outputId": "db001383-9b73-4244-f838-ac01b7aa9002"
      },
      "source": [
        "# baseline prediction for LogisticRegression only using categorical columns\n",
        "# categorical variables should only be one hot encoded for linear models\n",
        "pipe = Pipeline([('ohe', OneHotEncoder()), \n",
        "                 ('lr', LogisticRegression(max_iter=1000, multi_class='multinomial'))])\n",
        "\n",
        "lr_cat_model = pipe.fit(X_train_train.iloc[:, :4], y_train_train)\n",
        "y_pred = lr_cat_model.predict(X_val.iloc[:, :4])\n",
        "print('Balanced Accuracy:', balanced_accuracy_score(y_val, y_pred))\n",
        "print('F1 weighted:', f1_score(y_val, y_pred, average='weighted'))"
      ],
      "id": "owned-ethnic",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced Accuracy: 0.2353828710971568\n",
            "F1 weighted: 0.25130735345526656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "precious-family"
      },
      "source": [
        "##### Numeric columns <a class=\"anchor\" id=\"lr_continuous\"></a>"
      ],
      "id": "precious-family"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fitted-hammer",
        "outputId": "c0239e02-2d8b-4623-d8a3-8c4fa0abae06"
      },
      "source": [
        "# columns 5-12 are numeric\n",
        "~categorical_cols"
      ],
      "id": "fitted-hammer",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age          False\n",
              "Gender       False\n",
              "Education    False\n",
              "Country      False\n",
              "Ethnicity    False\n",
              "Nscore        True\n",
              "Escore        True\n",
              "Oscore        True\n",
              "Ascore        True\n",
              "Cscore        True\n",
              "Impulsive     True\n",
              "SS            True\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "signed-brand",
        "outputId": "8ec72b88-7424-4687-e400-a1b8071e11b5"
      },
      "source": [
        "# baseline prediction for LogisticRegression only using continuous columns\n",
        "pipe = Pipeline([('scaler', StandardScaler()), \n",
        "                 ('lr', LogisticRegression(max_iter=1000, multi_class='multinomial'))])\n",
        "\n",
        "lr_cont_model = pipe.fit(X_train_train.iloc[:, 5:], y_train_train)\n",
        "y_pred = lr_cont_model.predict(X_val.iloc[:, 5:])\n",
        "print('Balanced Accuracy:', balanced_accuracy_score(y_val, y_pred))\n",
        "print('F1 weighted:', f1_score(y_val, y_pred, average='weighted'))"
      ],
      "id": "signed-brand",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced Accuracy: 0.2306791092505378\n",
            "F1 weighted: 0.23222104614703948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "described-bridal"
      },
      "source": [
        "# possible continuous scalers\n",
        "cont_encoders = [{'random': [StandardScaler()]}, \n",
        "                 {'random': [MinMaxScaler()]}, \n",
        "                 {'random': [MaxAbsScaler()]},  \n",
        "                 {'random': [RobustScaler()]}, \n",
        "                 {'random': [QuantileTransformer()]}, \n",
        "                 {'random': [KBinsDiscretizer()]}]"
      ],
      "id": "described-bridal",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tight-program",
        "outputId": "91e2c23c-febe-4cd5-a5aa-5fa456493286"
      },
      "source": [
        "# find best encoder for Nscore column\n",
        "best_random_column(LogisticRegression(max_iter=1000, multi_class='multinomial'), cont_encoders, 6, 5)\n",
        "# find best encoder for Escore column\n",
        "best_random_column(LogisticRegression(max_iter=1000, multi_class='multinomial'), cont_encoders, 6, 6)\n",
        "# find best encoder for Oscore column\n",
        "best_random_column(LogisticRegression(max_iter=1000, multi_class='multinomial'), cont_encoders, 6, 7)\n",
        "# find best encoder for Ascore column\n",
        "best_random_column(LogisticRegression(max_iter=1000, multi_class='multinomial'), cont_encoders, 6, 8)\n",
        "# find best encoder for Cscore column\n",
        "best_random_column(LogisticRegression(max_iter=1000, multi_class='multinomial'), cont_encoders, 6, 9)\n",
        "# find best encoder for impulsive column\n",
        "best_random_column(LogisticRegression(max_iter=1000, multi_class='multinomial'), cont_encoders, 6, 10)\n",
        "# find best encoder for SS column\n",
        "best_random_column(LogisticRegression(max_iter=1000, multi_class='multinomial'), cont_encoders, 6, 11)"
      ],
      "id": "tight-program",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KBinsDiscretizer(encode='onehot', n_bins=5, strategy='quantile')\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KBinsDiscretizer(encode='onehot', n_bins=5, strategy='quantile')\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MaxAbsScaler(copy=True)\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "QuantileTransformer(copy=True, ignore_implicit_zeros=False, n_quantiles=1000,\n",
            "                    output_distribution='uniform', random_state=None,\n",
            "                    subsample=100000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "collective-neutral"
      },
      "source": [
        "For columns that the best scaler is QuantileTransformer or KBinsDiscretizer, try tuning hyperparameters."
      ],
      "id": "collective-neutral"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "experienced-diabetes"
      },
      "source": [
        "# hyperparameter grid for QuantileTransformer\n",
        "nquantiles = [50, 100, 150, 200, 250]\n",
        "dist = ['uniform', 'normal']\n",
        "\n",
        "quant_hyperparams = [{'random': [QuantileTransformer()]}, \n",
        "                     {'random__n_quantiles': nquantiles}, \n",
        "                     {'random__output_distribution': dist}]"
      ],
      "id": "experienced-diabetes",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suspended-reasoning"
      },
      "source": [
        "# hyperparameter grid for KBinsDiscretizer\n",
        "nbins = [3, 5, 7, 9, 11]\n",
        "encoding = ['one-hot', 'ordinal']\n",
        "strategy = ['uniform', 'quantile', 'kmeans']\n",
        "\n",
        "kbins_hyperparams = [{'random': [KBinsDiscretizer()]}, \n",
        "                     {'random__n_bins': nbins}, \n",
        "                     {'random__encode': encoding},\n",
        "                     {'random__strategy': strategy}]"
      ],
      "id": "suspended-reasoning",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exempt-manchester",
        "outputId": "e3f2031a-a0ec-4cad-d2ee-6632b97e67a5"
      },
      "source": [
        "# find best QuantileTransformer hyperparameters for Nscore column, default hyperparams are best\n",
        "best_random_column_tuning(LogisticRegression(max_iter=1000, multi_class='multinomial'), QuantileTransformer(), quant_hyperparams, 10, 5)"
      ],
      "id": "exempt-manchester",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "QuantileTransformer(copy=True, ignore_implicit_zeros=False, n_quantiles=150,\n",
            "                    output_distribution='uniform', random_state=None,\n",
            "                    subsample=100000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noble-escape",
        "outputId": "2fb86a18-ed70-4ecb-a2c7-6e8450c75897"
      },
      "source": [
        "# find best KBinsDiscretizer hyperparameters for Escore column, strategy='uniform' is best\n",
        "best_random_column_tuning(LogisticRegression(max_iter=1000, multi_class='multinomial'), KBinsDiscretizer(), kbins_hyperparams, 30, 6)"
      ],
      "id": "noble-escape",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
            "KBinsDiscretizer(encode='onehot', n_bins=11, strategy='quantile')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.7s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "super-overhead",
        "outputId": "15f3e509-229d-49de-a0dd-0c5ac461e567"
      },
      "source": [
        "# find best KBinsDiscretizer hyperparameters for Oscore column, default hyperparameters are best\n",
        "best_random_column_tuning(LogisticRegression(max_iter=1000, multi_class='multinomial'), KBinsDiscretizer(), kbins_hyperparams, 30, 7)"
      ],
      "id": "super-overhead",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
            "KBinsDiscretizer(encode='onehot', n_bins=3, strategy='quantile')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duplicate-oregon",
        "outputId": "281a7ef5-c274-4965-9ed6-60b44d45a6f0"
      },
      "source": [
        "# find best QuantileTransformer hyperparameters for impulsive column, default hyperparams are best\n",
        "best_random_column_tuning(LogisticRegression(max_iter=1000, multi_class='multinomial'), QuantileTransformer(), quant_hyperparams, 10, 10)"
      ],
      "id": "duplicate-oregon",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "QuantileTransformer(copy=True, ignore_implicit_zeros=False, n_quantiles=1000,\n",
            "                    output_distribution='uniform', random_state=None,\n",
            "                    subsample=100000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "worse-plaza",
        "outputId": "c3b4f980-2bd7-41f8-bf71-7e06af86bf7d"
      },
      "source": [
        "# using specific transformers for each column made the performace of the model marginally better in terms of f-1\n",
        "quant_pipe = Pipeline([('qt', QuantileTransformer())])\n",
        "\n",
        "min_max_pipe = Pipeline([('mms', MinMaxScaler())])\n",
        "\n",
        "kbins_pipe = Pipeline([('kbins', KBinsDiscretizer())])\n",
        "\n",
        "kbins_uniform_pipe = Pipeline([('kbins', KBinsDiscretizer(strategy='uniform'))])\n",
        "\n",
        "stan_pipe = Pipeline([('ss', StandardScaler())])\n",
        "\n",
        "continuous_pipe = ColumnTransformer([('quantile', quant_pipe,  ['Nscore', 'Impulsive']),\n",
        "                                      ('min_max',  min_max_pipe, ['Cscore']),\n",
        "                                      ('k_bins',  kbins_pipe, ['Oscore']), \n",
        "                                      ('k_bins_uniform',  kbins_uniform_pipe, ['Escore']), \n",
        "                                      ('standard',  stan_pipe, ['Ascore', 'SS'])])\n",
        "\n",
        "pipe = Pipeline([('cont_pipe', continuous_pipe), \n",
        "                 ('lr', LogisticRegression(max_iter=1000, multi_class='multinomial'))])\n",
        "\n",
        "lr_cont_model = pipe.fit(X_train_train.iloc[:, 5:], y_train_train)\n",
        "y_pred = lr_cont_model.predict(X_val.iloc[:, 5:])\n",
        "print('Balanced Accuracy:', balanced_accuracy_score(y_val, y_pred))\n",
        "print('F1 weighted:', f1_score(y_val, y_pred, average='weighted'))"
      ],
      "id": "worse-plaza",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced Accuracy: 0.23159267980696555\n",
            "F1 weighted: 0.24739590681126414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fitting-kelly"
      },
      "source": [
        "#### Put together categorical and continuous columns <a class=\"anchor\" id=\"lr_combined_encoders\"></a>"
      ],
      "id": "fitting-kelly"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dangerous-pressing",
        "outputId": "8da27fc1-9be7-4e4d-b5e2-2ccdbd868f80"
      },
      "source": [
        "# baseline comparison, putting categorical and continuous columns together for predicting\n",
        "categorical_cols = (X.dtypes == 'object')\n",
        "\n",
        "categorical_pipe = Pipeline([('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "continuous_pipe = Pipeline([('scaler', StandardScaler())])\n",
        "\n",
        "preprocessing = ColumnTransformer([('categorical', categorical_pipe,  categorical_cols),\n",
        "                                   ('continuous',  continuous_pipe, ~categorical_cols)])\n",
        "\n",
        "pipe = Pipeline([('preprocessing', preprocessing), \n",
        "                 ('lr', LogisticRegression(max_iter=1000, multi_class='multinomial'))])\n",
        "\n",
        "fit_predict_pipe(X_train_train, y_train_train, X_val, y_val, pipe)"
      ],
      "id": "dangerous-pressing",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced Accuracy: 0.29748756247203456\n",
            "F1 weighted: 0.33522357656205837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fleet-fairy",
        "outputId": "264d6c07-1ffa-4026-e040-ffe57ab44d05"
      },
      "source": [
        "# using specific transformers for columns hurt the model\n",
        "quant_pipe = Pipeline([('qt', QuantileTransformer())])\n",
        "\n",
        "min_max_pipe = Pipeline([('mms', MinMaxScaler())])\n",
        "\n",
        "kbins_pipe = Pipeline([('kbins', KBinsDiscretizer())])\n",
        "\n",
        "kbins_uniform_pipe = Pipeline([('kbins', KBinsDiscretizer(strategy='uniform'))])\n",
        "\n",
        "stan_pipe = Pipeline([('ss', StandardScaler())])\n",
        "\n",
        "preprocessing = ColumnTransformer([('ohe',  OneHotEncoder(), categorical_cols), \n",
        "                                   ('quantile', quant_pipe,  ['Nscore', 'Impulsive']),\n",
        "                                   ('min_max',  min_max_pipe, ['Cscore']),\n",
        "                                   ('k_bins',  kbins_pipe, ['Oscore']), \n",
        "                                   ('k_bins_uniform',  kbins_uniform_pipe, ['Escore']), \n",
        "                                   ('standard',  stan_pipe, ['Ascore', 'SS'])])\n",
        "\n",
        "pipe = Pipeline([('preprocessing', preprocessing), \n",
        "                 ('lr', LogisticRegression(max_iter=1000, multi_class='multinomial'))])\n",
        "\n",
        "fit_predict_pipe(X_train_train, y_train_train, X_val, y_val, pipe)"
      ],
      "id": "fleet-fairy",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced Accuracy: 0.2915788519049389\n",
            "F1 weighted: 0.32972758853673834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "structured-server"
      },
      "source": [
        "#### Search for best hyperparameters <a class=\"anchor\" id=\"lr_hyperparameters\"></a>"
      ],
      "id": "structured-server"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fabulous-process",
        "outputId": "3a054cd2-9426-433b-a8ad-e1f82bd520f4"
      },
      "source": [
        "# before hyperparameter tuning\n",
        "categorical_cols = (X.dtypes == 'object')\n",
        "\n",
        "categorical_pipe = Pipeline([('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "continuous_pipe = Pipeline([('scaler', StandardScaler())])\n",
        "\n",
        "preprocessing = ColumnTransformer([('categorical', categorical_pipe,  categorical_cols),\n",
        "                                   ('continuous',  continuous_pipe, ~categorical_cols)])\n",
        "\n",
        "pipe = Pipeline([('preprocessing', preprocessing), \n",
        "                 ('random', LogisticRegression(max_iter=1000, multi_class='multinomial'))])\n",
        "\n",
        "fit_predict_pipe(X_train_train, y_train_train, X_val, y_val, pipe)"
      ],
      "id": "fabulous-process",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced Accuracy: 0.29748756247203456\n",
            "F1 weighted: 0.33522357656205837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "based-probability"
      },
      "source": [
        "# grid for LogisticRegression\n",
        "penalty = ['l1', 'l2', 'none']\n",
        "tol = [float(x) for x in np.logspace(-1, -7, 7)]\n",
        "C = [float(x) for x in np.logspace(3, -3, 7)]\n",
        "fit_intercept = [True, False]\n",
        "class_weight = ['balanced', None]\n",
        "solver = ['newton-cg', 'lbfgs', 'sag', 'saga']    # liblinear does not support multinomial\n",
        "\n",
        "hyperparameters = [{'random': [LogisticRegression(multi_class='multinomial', max_iter=1000)],\n",
        "                    'random__penalty': penalty,\n",
        "                    'random__tol': tol,\n",
        "                    'random__C': C,\n",
        "                    'random__fit_intercept': fit_intercept,\n",
        "                    'random__class_weight': class_weight,\n",
        "                    'random__solver': solver}]"
      ],
      "id": "based-probability",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "light-philippines",
        "outputId": "66327ec4-cb17-47ad-d939-4a193307454f"
      },
      "source": [
        "# tuning hyperparameters hurt the model\n",
        "fit_and_predict_random(hyperparameters, 1000)"
      ],
      "id": "light-philippines",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   22.6s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.3min\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "discrete-reply"
      },
      "source": [
        "Tuning the hyperparameters actually hurt the model performance on the validation set. The default hyperparameters provided by Sci-kit learn are better for predicting the data."
      ],
      "id": "discrete-reply"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "educational-apparel"
      },
      "source": [
        "### RandomForest <a class=\"anchor\" id=\"RandomForest\"></a>"
      ],
      "id": "educational-apparel"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "changed-operator"
      },
      "source": [
        "#### SMOTE <a class=\"anchor\" id=\"rf_smote\"></a>"
      ],
      "id": "changed-operator"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hybrid-disorder"
      },
      "source": [
        "# baseline RandomForest performance without SMOTE\n",
        "categorical_cols = (X.dtypes == 'object')\n",
        "\n",
        "categorical_pipe = Pipeline([('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "continuous_pipe = Pipeline([('scaler', StandardScaler())])\n",
        "\n",
        "preprocessing = ColumnTransformer([('categorical', categorical_pipe,  categorical_cols),\n",
        "                                   ('continuous',  continuous_pipe, ~categorical_cols)])\n",
        "\n",
        "pipe = Pipeline([('preprocess', preprocessing),\n",
        "                 ('rf', RandomForestClassifier())])\n",
        "\n",
        "fit_predict_pipe(X_train_train, y_train_train, X_val, y_val, pipe)"
      ],
      "id": "hybrid-disorder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "persistent-necklace"
      },
      "source": [
        "# try adding SMOTE to RandomForest\n",
        "pipe = Pipeline([('preprocess', preprocessing),\n",
        "                 ('random', SMOTE()),\n",
        "                 ('rf', RandomForestClassifier())])"
      ],
      "id": "persistent-necklace",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "popular-mediterranean"
      },
      "source": [
        "# hyperparameter grid for SMOTE\n",
        "strategy = ['minority', 'not minority', 'not majority', 'all', 'auto']\n",
        "neighbors = [1, 3, 5, 7, 9]\n",
        "\n",
        "hyperparameters = [{'random': [SMOTE()],\n",
        "                    'random__sampling_strategy': strategy,\n",
        "                    'random__k_neighbors': neighbors}]"
      ],
      "id": "popular-mediterranean",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spectacular-pacific"
      },
      "source": [
        "# adding SMOTE seems to help RandomForest, using k_neighbors=3, sampling_strategy='not majority'\n",
        "fit_and_predict_random(hyperparameters, 25)"
      ],
      "id": "spectacular-pacific",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "physical-monaco"
      },
      "source": [
        "The concern about imbalanced data doesn't seem to affect the models, they make better predictions without considering it."
      ],
      "id": "physical-monaco"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "after-cinema"
      },
      "source": [
        "#### Column Transformations <a class=\"anchor\" id=\"rf_encoding\"></a>"
      ],
      "id": "after-cinema"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "better-railway"
      },
      "source": [
        "##### Categorical columns <a class=\"anchor\" id=\"rf_categorical\"></a>"
      ],
      "id": "better-railway"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "straight-parish"
      },
      "source": [
        "# baseline prediction for RandomForest only using categorical columns\n",
        "pipe = Pipeline([('ohe', OneHotEncoder()), \n",
        "                 ('smote', imblearn.over_sampling.SMOTE(k_neighbors=3, sampling_strategy='not minority')),\n",
        "                 ('rf', RandomForestClassifier())])\n",
        "\n",
        "rf_cat_model = pipe.fit(X_train_train.iloc[:, :4], y_train_train)\n",
        "y_pred = rf_cat_model.predict(X_val.iloc[:, :4])\n",
        "print('Balanced Accuracy:', balanced_accuracy_score(y_val, y_pred))\n",
        "print('F1 weighted:', f1_score(y_val, y_pred, average='weighted'))"
      ],
      "id": "straight-parish",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "immune-flour"
      },
      "source": [
        "# possible category encoders\n",
        "cat_encoders = [{'random': [CatBoostEncoder()]}, \n",
        "                {'random': [GLMMEncoder()]}, \n",
        "                {'random': [HashingEncoder()]},  \n",
        "                {'random': [JamesSteinEncoder()]}, \n",
        "                {'random': [LeaveOneOutEncoder()]}, \n",
        "                {'random': [MEstimateEncoder()]}, \n",
        "                {'random': [OneHotEncoder()]}, \n",
        "                {'random': [OrdinalEncoder()]}, \n",
        "                {'random': [TargetEncoder()]}, \n",
        "                {'random': [WOEEncoder()]}]"
      ],
      "id": "immune-flour",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "written-homework"
      },
      "source": [
        "# find best encoder for age column\n",
        "best_random_column(RandomForestClassifier(), cat_encoders, 10, 0)\n",
        "# find best encoder for education column\n",
        "best_random_column(RandomForestClassifier(), cat_encoders, 10, 2)\n",
        "# find best encoder for country column\n",
        "best_random_column(RandomForestClassifier(), cat_encoders, 10, 3)\n",
        "# find best encoder for ethnicity column\n",
        "best_random_column(RandomForestClassifier(), cat_encoders, 10, 4)"
      ],
      "id": "written-homework",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fatal-frederick"
      },
      "source": [
        "# glm encoder is best for all \n",
        "glm_pipe = Pipeline([('glm', GLMMEncoder())])\n",
        "\n",
        "# since gender is binary in this dataset, doesn't need anything fancy\n",
        "one_hot_pipe = Pipeline([('ohe', OneHotEncoder())])\n",
        "\n",
        "categorical_pipe = ColumnTransformer([('other_cats', glm_pipe,  ['Age', 'Education', 'Country', 'Ethnicity']),\n",
        "                                      ('gender',  one_hot_pipe, ['Gender'])])\n",
        "\n",
        "pipe = Pipeline([('cat_pipe', categorical_pipe), \n",
        "                 ('smote', imblearn.over_sampling.SMOTE(k_neighbors=3, sampling_strategy='not minority')),\n",
        "                 ('rf', RandomForestClassifier())])\n",
        "\n",
        "# using specific encoders for each column hurt the model performance\n",
        "fit_predict_pipe(X_train_train, y_train_train, X_val, y_val, pipe)"
      ],
      "id": "fatal-frederick",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "institutional-portal"
      },
      "source": [
        "##### Numeric columns <a class=\"anchor\" id=\"rf_continuous\"></a>"
      ],
      "id": "institutional-portal"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "current-scanning"
      },
      "source": [
        "# baseline prediction performance before specifically encoding each column\n",
        "pipe = Pipeline([('ss', StandardScaler()), \n",
        "                 ('smote', imblearn.over_sampling.SMOTE(k_neighbors=3, sampling_strategy='not minority')),\n",
        "                 ('rf', RandomForestClassifier())])\n",
        "\n",
        "rf_cont_model = pipe.fit(X_train_train.iloc[:, 5:], y_train_train)\n",
        "y_pred = rf_cont_model.predict(X_val.iloc[:, 5:])\n",
        "print('Balanced Accuracy:', balanced_accuracy_score(y_val, y_pred))\n",
        "print('F1 weighted:', f1_score(y_val, y_pred, average='weighted'))"
      ],
      "id": "current-scanning",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adjustable-acrobat"
      },
      "source": [
        "# find best encoder for Nscore column\n",
        "best_random_column(RandomForestClassifier(), cont_encoders, 6, 5)\n",
        "# find best encoder for Escore column\n",
        "best_random_column(RandomForestClassifier(), cont_encoders, 6, 6)\n",
        "# find best encoder for Oscore column\n",
        "best_random_column(RandomForestClassifier(), cont_encoders, 6, 7)\n",
        "# find best encoder for Ascore column\n",
        "best_random_column(RandomForestClassifier(), cont_encoders, 6, 8)\n",
        "# find best encoder for Cscore column\n",
        "best_random_column(RandomForestClassifier(), cont_encoders, 6, 9)\n",
        "# find best encoder for impulsive column\n",
        "best_random_column(RandomForestClassifier(), cont_encoders, 6, 10)\n",
        "# find best encoder for SS column\n",
        "best_random_column(RandomForestClassifier(), cont_encoders, 6, 11)"
      ],
      "id": "adjustable-acrobat",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "minimal-extension"
      },
      "source": [
        "# find best QuantileTransformer hyperparameters for Oscore column, default hyperparams are best\n",
        "best_random_column_tuning(RandomForestClassifier(), QuantileTransformer(), quant_hyperparams, 10, 7)"
      ],
      "id": "minimal-extension",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ranking-taste"
      },
      "source": [
        "# find best QuantileTransformer hyperparameters for Cscore column, default hyperparams are best\n",
        "best_random_column_tuning(RandomForestClassifier(), QuantileTransformer(), quant_hyperparams, 10, 9)"
      ],
      "id": "ranking-taste",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "difficult-shaft"
      },
      "source": [
        "# find best QuantileTransformer hyperparameters for impulsive column, n_quantiles=50 is best\n",
        "best_random_column_tuning(RandomForestClassifier(), QuantileTransformer(), quant_hyperparams, 10, 10)"
      ],
      "id": "difficult-shaft",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "powerful-empty"
      },
      "source": [
        "# using specific encoders for each column made the performace of the model better\n",
        "stan_pipe = Pipeline([('ss', StandardScaler())])\n",
        "\n",
        "min_max_pipe = Pipeline([('mms', MinMaxScaler())])\n",
        "\n",
        "quant_pipe = Pipeline([('quantile', QuantileTransformer())])\n",
        "\n",
        "quant_50_pipe = Pipeline([('quantile', QuantileTransformer(n_quantiles=50))])\n",
        "\n",
        "continuous_pipe = ColumnTransformer([('standard',  stan_pipe, ['Nscore', 'Ascore', 'SS']), \n",
        "                                     ('min_max',  min_max_pipe, ['Escore']), \n",
        "                                     ('quantile',  quant_pipe, ['Oscore', 'Cscore']),\n",
        "                                     ('quantile_50',  quant_50_pipe, ['Impulsive'])])\n",
        "\n",
        "pipe = Pipeline([('cont_pipe', continuous_pipe), \n",
        "                 ('smote', imblearn.over_sampling.SMOTE(k_neighbors=3, sampling_strategy='not minority')),\n",
        "                 ('etc', ExtraTreesClassifier())])\n",
        "\n",
        "etc_cont_model = pipe.fit(X_train_train.iloc[:, 5:], y_train_train)\n",
        "y_pred = etc_cont_model.predict(X_val.iloc[:, 5:])\n",
        "print('Balanced Accuracy:', balanced_accuracy_score(y_val, y_pred))\n",
        "print('F1 weighted:', f1_score(y_val, y_pred, average='weighted'))"
      ],
      "id": "powerful-empty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "proprietary-permit"
      },
      "source": [
        "#### Combine categorical and continuous columns back together <a class=\"anchor\" id=\"rf_combined_encoders\"></a>"
      ],
      "id": "proprietary-permit"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "intensive-internet"
      },
      "source": [
        "# baseline comparison, putting categorical and continuous columns together for predicting\n",
        "categorical_cols = (X.dtypes == 'object')\n",
        "\n",
        "categorical_pipe = Pipeline([('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "continuous_pipe = Pipeline([('scaler', StandardScaler())])\n",
        "\n",
        "preprocessing = ColumnTransformer([('categorical', categorical_pipe,  categorical_cols),\n",
        "                                   ('continuous',  continuous_pipe, ~categorical_cols)])\n",
        "\n",
        "pipe = Pipeline([('preprocessing', preprocessing), \n",
        "                 ('smote', imblearn.over_sampling.SMOTE(k_neighbors=3, sampling_strategy='not minority')),\n",
        "                 ('rf', RandomForestClassifier())])\n",
        "\n",
        "fit_predict_pipe(X_train_train, y_train_train, X_val, y_val, pipe)"
      ],
      "id": "intensive-internet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecological-copper"
      },
      "source": [
        "# using specific transformers for columns helped the model slightly\n",
        "stan_pipe = Pipeline([('ss', StandardScaler())])\n",
        "\n",
        "min_max_pipe = Pipeline([('mms', MinMaxScaler())])\n",
        "\n",
        "quant_pipe = Pipeline([('quantile', QuantileTransformer())])\n",
        "\n",
        "quant_50_pipe = Pipeline([('quantile', QuantileTransformer(n_quantiles=50))])\n",
        "\n",
        "preprocessing = ColumnTransformer([('ohe',  OneHotEncoder(), categorical_cols), \n",
        "                                   ('standard',  stan_pipe, ['Nscore', 'Ascore', 'SS']), \n",
        "                                   ('min_max',  min_max_pipe, ['Escore']), \n",
        "                                   ('quantile',  quant_pipe, ['Oscore', 'Cscore']),\n",
        "                                   ('quantile_50',  quant_50_pipe, ['Impulsive'])])\n",
        "\n",
        "pipe = Pipeline([('preprocessing', preprocessing),\n",
        "                 ('smote', imblearn.over_sampling.SMOTE(k_neighbors=3, sampling_strategy='not minority')),\n",
        "                 ('rf', RandomForestClassifier())])\n",
        "\n",
        "fit_predict_pipe(X_train_train, y_train_train, X_val, y_val, pipe)"
      ],
      "id": "ecological-copper",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "signed-acrobat"
      },
      "source": [
        "#### Search for best hyperparameters <a class=\"anchor\" id=\"rf_hyperparameters\"></a>"
      ],
      "id": "signed-acrobat"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "designing-uniform"
      },
      "source": [
        "# before hyperparameter tuning\n",
        "stan_pipe = Pipeline([('ss', StandardScaler())])\n",
        "\n",
        "min_max_pipe = Pipeline([('mms', MinMaxScaler())])\n",
        "\n",
        "quant_pipe = Pipeline([('quantile', QuantileTransformer())])\n",
        "\n",
        "quant_50_pipe = Pipeline([('quantile', QuantileTransformer(n_quantiles=50))])\n",
        "\n",
        "preprocessing = ColumnTransformer([('ohe',  OneHotEncoder(), categorical_cols), \n",
        "                                   ('standard',  stan_pipe, ['Nscore', 'Ascore', 'SS']), \n",
        "                                   ('min_max',  min_max_pipe, ['Escore']), \n",
        "                                   ('quantile',  quant_pipe, ['Oscore', 'Cscore']),\n",
        "                                   ('quantile_50',  quant_50_pipe, ['Impulsive'])])\n",
        "\n",
        "pipe = Pipeline([('preprocessing', preprocessing), \n",
        "                 ('smote', imblearn.over_sampling.SMOTE(k_neighbors=3, sampling_strategy='not minority')),\n",
        "                 ('random', RandomForestClassifier())])\n",
        "\n",
        "fit_predict_pipe(X_train_train, y_train_train, X_val, y_val, pipe)"
      ],
      "id": "designing-uniform",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "palestinian-black"
      },
      "source": [
        "# grid for RandomForest\n",
        "max_depth = [int(x) for x in np.linspace(25, 75, 3)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [int(x) for x in np.linspace(2, 10, 5)]\n",
        "min_samples_leaf = [int(x) for x in np.linspace(1, 9, 5)]\n",
        "max_features = ['auto', 'sqrt', 'log2', None]\n",
        "bootstrap = [True, False]\n",
        "class_weight = ['balanced', 'balanced_subsample', None]\n",
        "\n",
        "hyperparameters = [{'random': [RandomForestClassifier()],\n",
        "                    'random__max_depth': max_depth,\n",
        "                    'random__min_samples_split': min_samples_split,\n",
        "                    'random__min_samples_leaf': min_samples_leaf,\n",
        "                    'random__max_features': max_features,\n",
        "                    'random__bootstrap': bootstrap,\n",
        "                    'random__class_weight' : class_weight}]"
      ],
      "id": "palestinian-black",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liquid-feelings"
      },
      "source": [
        "# tuning hyperparameters hurt the model\n",
        "fit_and_predict_random(hyperparameters, 1000)"
      ],
      "id": "liquid-feelings",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roman-finger"
      },
      "source": [
        "Again, tuning the hyperparameters hurt the model's performance on the validation set. The default values provided by Sci-kit learn are better for predicting the data."
      ],
      "id": "roman-finger"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coordinate-northeast"
      },
      "source": [
        "### Final Model <a class=\"anchor\" id=\"Final_model\"></a>"
      ],
      "id": "coordinate-northeast"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outstanding-disaster"
      },
      "source": [
        "For my final model, I am choosing the RandomForest model with tuned steps for preprocessing the numeric columns along with incorporating SMOTE into my pipeline."
      ],
      "id": "outstanding-disaster"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "covered-contrary"
      },
      "source": [
        "# see how my model performs on the test data!\n",
        "stan_pipe = Pipeline([('ss', StandardScaler())])\n",
        "\n",
        "min_max_pipe = Pipeline([('mms', MinMaxScaler())])\n",
        "\n",
        "quant_pipe = Pipeline([('quantile', QuantileTransformer())])\n",
        "\n",
        "quant_50_pipe = Pipeline([('quantile', QuantileTransformer(n_quantiles=50))])\n",
        "\n",
        "preprocessing = ColumnTransformer([('ohe',  OneHotEncoder(), categorical_cols), \n",
        "                                   ('standard',  stan_pipe, ['Nscore', 'Ascore', 'SS']), \n",
        "                                   ('min_max',  min_max_pipe, ['Escore']), \n",
        "                                   ('quantile',  quant_pipe, ['Oscore', 'Cscore']),\n",
        "                                   ('quantile_50',  quant_50_pipe, ['Impulsive'])])\n",
        "\n",
        "pipe = Pipeline([('preprocessing', preprocessing), \n",
        "                 ('smote', SMOTE(k_neighbors=3, sampling_strategy='not minority')),\n",
        "                 ('random', RandomForestClassifier())])\n",
        "\n",
        "fit_predict_pipe(X_train, y_train, X_test, y_test, pipe)"
      ],
      "id": "covered-contrary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "instrumental-english"
      },
      "source": [
        "Using my tuned and fully trained model, I am able to achieve a F1-weighted of 0.413 on the test data which is about ~0.07 better than my basic original model performed on the validation data. Tuning the preprocessing steps and including SMOTE in my pipeline improved my ability to predict with a random forest model."
      ],
      "id": "instrumental-english"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hungry-penny"
      },
      "source": [
        "### Conclusion <a class=\"anchor\" id=\"Conclusion\"></a>\n",
        "In the end, a RandomForest model with the default hyperparameters performed the best on the validation set and yielded an F1-weighted score of 0.413 and a balanced accuracy score of 0.315. Before tuning my preprocessing steps and adding SMOTE to my pipeline, my F1-weighted score was 0.348 and my balanced accuracy score was 0.294. \n",
        "\n",
        "All the categorical columns performed best with one-hot encoding, which makes sense with respsect to the distribution of labels given the different levels of each categorical variable. For each categorical variable, the mean level of consumption differed for each level of the variable itself.\n",
        "\n",
        "For the most part, the personality scores were roughly normally distributed, but transforming each column with its ideal transformer yielded better results than just using the StandardScaler on all personality scores.\n",
        "\n",
        "For the ideal SMOTE parameters, the RandomizedSearchCV chose the best strategy as 'not minority', which may be an artifact of the scoring criteria used by the RandomSearchCV. Since RandomSearchCV was trying to maximize the F1-weighted score, perhaps it decided that predicting the minority class, class 4 (\"Used in the last month\"), was too difficult to predict, so instead it sampled all other classes in an effort to try and increase F1-weighted score.\n",
        "\n",
        "Tuning the hyperparameters yielded worse a balanced accuracy score and a worse F1-weighted score than the default hyperparameters. I think this has to do with the overall difficulty of classifying the data. There are 7 labels the classifier is trying to predict and the reality of the distances between the labels aren't very far apart. For instance, is a cannabis user who last used cannabis a week ago versus a month ago that simple to differentiate? I think this is a very difficult prediction to make, which resulted in a lot of misclassifications. \n",
        "\n",
        "A better classification problem may be to predict whether someone has used a drug before or has never used a drug before. A model that could accurately predict between those two classes would be more useful in a business context as well.\n",
        "\n",
        "#### Limitations\n",
        "It's also important to point out the limitations of this data. Based on the demographic information collected in this dataset, a majority of the participants are between the ages of 18-34 years old, are white, are in either the UK or the USA, and have some college experience. Based on the demographic information, I would not try to use a model trained on this data to try and predict drug consumption for the general population. The demographics of this dataset are not well distributed and therefore, are probably not representative of the population as a whole. "
      ],
      "id": "hungry-penny"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "incident-bikini"
      },
      "source": [
        "### Future Directions <a class=\"anchor\" id=\"Future_directions\"></a>\n",
        "Along with trying a modified classification problem, future work could look into analyzing the features in the dataset to see if there is mulitcollinearity in the data and if so, remove some highly correlated features.\n",
        "\n",
        "Assuming the simplified classification problem yielded better results, one could also look into the feature importances of the attributes provided in the dataset to, again, try and remove some weakly-predictive features and obtain a simpler, more accurate model.\n",
        "\n",
        "A final idea I had was to create an overall personality column that classifies participants into certain personality labels based on their personality trait scores. For example, high impulsivity and high sensation seeking could correspond to an \"addictive\" personality and that attribute could be used to predict drug consumption, rather than using impulsivity and sensation seeking separately."
      ],
      "id": "incident-bikini"
    }
  ]
}